{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_TFRecords.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCdukfFx9Cr_",
        "colab_type": "code",
        "outputId": "30da9dc2-12ff-4d4b-cd8d-1c00338a768c",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1347639b-4496-4f2c-b417-a2b0b382e530\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1347639b-4496-4f2c-b417-a2b0b382e530\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving read_TFRecord.py to read_TFRecord.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-61dhei9-Ikb",
        "colab_type": "code",
        "outputId": "99513216-0f39-418e-d6ee-6ccc68b000c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# !rm TFRecords.py\n",
        "!rm read_TFRecord.py\n",
        "# !rm train.tfrecords\n",
        "# !rm eval.tfrecords\n",
        "# !rm validation.tfrecords\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar-10-batches-py\t eval.tfrecords  train.tfrecords\n",
            "cifar-10-python.tar.gz\t sample_data\t validation.tfrecords\n",
            "cutout_read_TFRecord.py  TFRecords.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAIS_2-w-ahm",
        "colab_type": "code",
        "outputId": "efa6ae55-9c0c-4839-b730-61eec9dfe096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "!python TFRecords.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From TFRecords.py:42: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
            "Generating train.tfrecords\n",
            "WARNING:tensorflow:From TFRecords.py:76: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From TFRecords.py:65: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Generating validation.tfrecords\n",
            "Generating eval.tfrecords\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJIhsaHQ-iCf",
        "colab_type": "code",
        "outputId": "234e51e3-f788-49c2-fdae-99f11acf5bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python read_TFRecord.py\n",
        "# !python cutout_read_TFRecord.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From read_TFRecord.py:16: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
            "\n",
            "dropout --  0.1\n",
            "batch_size 64\n",
            "num_filters 20\n",
            "layers per dense block 8\n",
            "2019-09-07 10:32:06.431312: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-07 10:32:06.465908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-07 10:32:06.466532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-07 10:32:06.466775: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-07 10:32:06.467993: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-07 10:32:06.469268: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-07 10:32:06.469586: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-07 10:32:06.471041: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-07 10:32:06.472325: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-07 10:32:06.475882: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-07 10:32:06.475979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-07 10:32:06.476538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-07 10:32:06.477038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-07 10:32:06.490823: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-09-07 10:32:06.491034: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17632c0 executing computations on platform Host. Devices:\n",
            "2019-09-07 10:32:06.491059: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-07 10:32:06.597974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-07 10:32:06.598653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17639c0 executing computations on platform CUDA. Devices:\n",
            "2019-09-07 10:32:06.598686: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-09-07 10:32:06.598837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-07 10:32:06.599312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-07 10:32:06.599360: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-07 10:32:06.599380: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-07 10:32:06.599397: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-07 10:32:06.599417: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-07 10:32:06.599433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-07 10:32:06.599449: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-07 10:32:06.599465: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-07 10:32:06.599532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-07 10:32:06.600027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-07 10:32:06.600527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-07 10:32:06.600594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-07 10:32:06.601597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-07 10:32:06.601621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-07 10:32:06.601631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-07 10:32:06.601729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-07 10:32:06.602284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-07 10:32:06.602765: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-07 10:32:06.602804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From read_TFRecord.py:47: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From read_TFRecord.py:50: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From read_TFRecord.py:37: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
            "\n",
            "WARNING:tensorflow:From read_TFRecord.py:38: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
            "\n",
            "2019-09-07 10:32:06.666122: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: random_flip_left_right_true_75\n",
            "2019-09-07 10:32:06.666224: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: random_flip_left_right_false_76\n",
            "WARNING:tensorflow:From read_TFRecord.py:90: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "2019-09-07 10:32:14.324146: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: random_flip_left_right_true_181\n",
            "2019-09-07 10:32:14.324242: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: random_flip_left_right_false_182\n",
            "TrainEpochs number1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2019-09-07 10:33:00.865289: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-07 10:33:01.165115: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "624/624 [==============================] - 101s 162ms/step - loss: 1.7289 - acc: 0.3633\n",
            "Test Epochs number1/100\n",
            "156/156 [==============================] - 5s 34ms/step - loss: 1.6925 - acc: 0.4039\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number2/100\n",
            "624/624 [==============================] - 70s 113ms/step - loss: 1.3964 - acc: 0.4887\n",
            "Test Epochs number2/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 1.5015 - acc: 0.4883\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number3/100\n",
            "624/624 [==============================] - 70s 112ms/step - loss: 1.2083 - acc: 0.5644\n",
            "Test Epochs number3/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 1.2596 - acc: 0.5626\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number4/100\n",
            "624/624 [==============================] - 70s 112ms/step - loss: 1.0717 - acc: 0.6164\n",
            "Test Epochs number4/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 1.1850 - acc: 0.6029\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number5/100\n",
            "624/624 [==============================] - 70s 111ms/step - loss: 0.9801 - acc: 0.6524\n",
            "Test Epochs number5/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 1.0629 - acc: 0.6279\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number6/100\n",
            "624/624 [==============================] - 69s 111ms/step - loss: 0.9116 - acc: 0.6756\n",
            "Test Epochs number6/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.9315 - acc: 0.6776\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number7/100\n",
            "624/624 [==============================] - 69s 110ms/step - loss: 0.8529 - acc: 0.6988\n",
            "Test Epochs number7/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.8857 - acc: 0.6981\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number8/100\n",
            "624/624 [==============================] - 68s 110ms/step - loss: 0.8114 - acc: 0.7134\n",
            "Test Epochs number8/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.8426 - acc: 0.7096\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number9/100\n",
            "624/624 [==============================] - 69s 110ms/step - loss: 0.7681 - acc: 0.7304\n",
            "Test Epochs number9/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 1.0590 - acc: 0.6493\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number10/100\n",
            "624/624 [==============================] - 69s 110ms/step - loss: 0.7392 - acc: 0.7390\n",
            "Test Epochs number10/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.8518 - acc: 0.7123\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number11/100\n",
            "624/624 [==============================] - 69s 110ms/step - loss: 0.7104 - acc: 0.7516\n",
            "Test Epochs number11/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.7414 - acc: 0.7472\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number12/100\n",
            "624/624 [==============================] - 68s 110ms/step - loss: 0.6807 - acc: 0.7575\n",
            "Test Epochs number12/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 1.0727 - acc: 0.6681\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number13/100\n",
            "624/624 [==============================] - 69s 110ms/step - loss: 0.6572 - acc: 0.7687\n",
            "Test Epochs number13/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.8669 - acc: 0.7178\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number14/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.6393 - acc: 0.7773\n",
            "Test Epochs number14/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.7182 - acc: 0.7543\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number15/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.6240 - acc: 0.7772\n",
            "Test Epochs number15/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.7787 - acc: 0.7410\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number16/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.6054 - acc: 0.7883\n",
            "Test Epochs number16/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.7274 - acc: 0.7529\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number17/100\n",
            "624/624 [==============================] - 68s 110ms/step - loss: 0.5930 - acc: 0.7914\n",
            "Test Epochs number17/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.9005 - acc: 0.7150\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number18/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.5772 - acc: 0.7968\n",
            "Test Epochs number18/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6737 - acc: 0.7770\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number19/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.5593 - acc: 0.8031\n",
            "Test Epochs number19/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.8067 - acc: 0.7397\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number20/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.5533 - acc: 0.8050\n",
            "Test Epochs number20/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6873 - acc: 0.7708\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number21/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.5417 - acc: 0.8095\n",
            "Test Epochs number21/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6060 - acc: 0.7922\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number22/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.5328 - acc: 0.8121\n",
            "Test Epochs number22/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6863 - acc: 0.7632\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number23/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.5201 - acc: 0.8193\n",
            "Test Epochs number23/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6714 - acc: 0.7908\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number24/100\n",
            "624/624 [==============================] - 68s 108ms/step - loss: 0.5121 - acc: 0.8184\n",
            "Test Epochs number24/100\n",
            "156/156 [==============================] - 4s 25ms/step - loss: 0.7516 - acc: 0.7566\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number25/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.5018 - acc: 0.8241\n",
            "Test Epochs number25/100\n",
            "156/156 [==============================] - 4s 25ms/step - loss: 0.5875 - acc: 0.8028\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number26/100\n",
            "624/624 [==============================] - 68s 108ms/step - loss: 0.5046 - acc: 0.8244\n",
            "Test Epochs number26/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.7204 - acc: 0.7667\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number27/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4898 - acc: 0.8276\n",
            "Test Epochs number27/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6309 - acc: 0.7935\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number28/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4796 - acc: 0.8310\n",
            "Test Epochs number28/100\n",
            "156/156 [==============================] - 4s 25ms/step - loss: 0.6012 - acc: 0.8000\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number29/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4745 - acc: 0.8342\n",
            "Test Epochs number29/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6123 - acc: 0.8025\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number30/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4671 - acc: 0.8355\n",
            "Test Epochs number30/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.7010 - acc: 0.7686\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number31/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4634 - acc: 0.8363\n",
            "Test Epochs number31/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6169 - acc: 0.8007\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number32/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4543 - acc: 0.8402\n",
            "Test Epochs number32/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6309 - acc: 0.7992\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number33/100\n",
            "624/624 [==============================] - 67s 107ms/step - loss: 0.4482 - acc: 0.8422\n",
            "Test Epochs number33/100\n",
            "156/156 [==============================] - 4s 25ms/step - loss: 0.7171 - acc: 0.7733\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number34/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4451 - acc: 0.8433\n",
            "Test Epochs number34/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6081 - acc: 0.7982\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number35/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4363 - acc: 0.8469\n",
            "Test Epochs number35/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.5543 - acc: 0.8188\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number36/100\n",
            "624/624 [==============================] - 67s 107ms/step - loss: 0.4331 - acc: 0.8478\n",
            "Test Epochs number36/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6445 - acc: 0.7954\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number37/100\n",
            "624/624 [==============================] - 67s 107ms/step - loss: 0.4278 - acc: 0.8502\n",
            "Test Epochs number37/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.5741 - acc: 0.8146\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number38/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4231 - acc: 0.8496\n",
            "Test Epochs number38/100\n",
            "156/156 [==============================] - 4s 25ms/step - loss: 0.5578 - acc: 0.8211\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number39/100\n",
            "624/624 [==============================] - 68s 108ms/step - loss: 0.4190 - acc: 0.8514\n",
            "Test Epochs number39/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.5899 - acc: 0.8123\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number40/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4186 - acc: 0.8529\n",
            "Test Epochs number40/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.5849 - acc: 0.8168\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number41/100\n",
            "624/624 [==============================] - 67s 108ms/step - loss: 0.4104 - acc: 0.8558\n",
            "Test Epochs number41/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.5333 - acc: 0.8273\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number42/100\n",
            "624/624 [==============================] - 68s 108ms/step - loss: 0.4078 - acc: 0.8564\n",
            "Test Epochs number42/100\n",
            "156/156 [==============================] - 4s 25ms/step - loss: 0.5286 - acc: 0.8318\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number43/100\n",
            "624/624 [==============================] - 68s 108ms/step - loss: 0.3990 - acc: 0.8580\n",
            "Test Epochs number43/100\n",
            "156/156 [==============================] - 4s 25ms/step - loss: 0.6079 - acc: 0.8056\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number44/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.3980 - acc: 0.8603\n",
            "Test Epochs number44/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.5536 - acc: 0.8219\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number45/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.3966 - acc: 0.8608\n",
            "Test Epochs number45/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.5555 - acc: 0.8235\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number46/100\n",
            "624/624 [==============================] - 68s 108ms/step - loss: 0.3966 - acc: 0.8598\n",
            "Test Epochs number46/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.6141 - acc: 0.8115\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number47/100\n",
            "624/624 [==============================] - 68s 109ms/step - loss: 0.3915 - acc: 0.8590\n",
            "Test Epochs number47/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.5331 - acc: 0.8292\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number48/100\n",
            "624/624 [==============================] - 69s 110ms/step - loss: 0.3824 - acc: 0.8653\n",
            "Test Epochs number48/100\n",
            "156/156 [==============================] - 4s 26ms/step - loss: 0.5530 - acc: 0.8274\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number49/100\n",
            "624/624 [==============================] - 70s 112ms/step - loss: 0.3846 - acc: 0.8638\n",
            "Test Epochs number49/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 0.5625 - acc: 0.8247\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number50/100\n",
            "624/624 [==============================] - 72s 115ms/step - loss: 0.3780 - acc: 0.8682\n",
            "Test Epochs number50/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 0.5704 - acc: 0.8201\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number51/100\n",
            "624/624 [==============================] - 72s 115ms/step - loss: 0.3737 - acc: 0.8694\n",
            "Test Epochs number51/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 0.5502 - acc: 0.8231\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number52/100\n",
            "624/624 [==============================] - 72s 116ms/step - loss: 0.3711 - acc: 0.8700\n",
            "Test Epochs number52/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 0.5300 - acc: 0.8284\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number53/100\n",
            "624/624 [==============================] - 72s 116ms/step - loss: 0.3684 - acc: 0.8698\n",
            "Test Epochs number53/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5491 - acc: 0.8258\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number54/100\n",
            "624/624 [==============================] - 72s 116ms/step - loss: 0.3673 - acc: 0.8701\n",
            "Test Epochs number54/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 0.5371 - acc: 0.8322\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number55/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3679 - acc: 0.8694\n",
            "Test Epochs number55/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5860 - acc: 0.8207\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number56/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3602 - acc: 0.8713\n",
            "Test Epochs number56/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5503 - acc: 0.8303\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number57/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3542 - acc: 0.8735\n",
            "Test Epochs number57/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5010 - acc: 0.8410\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number58/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3524 - acc: 0.8759\n",
            "Test Epochs number58/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5687 - acc: 0.8280\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number59/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3512 - acc: 0.8767\n",
            "Test Epochs number59/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5356 - acc: 0.8313\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number60/100\n",
            "624/624 [==============================] - 74s 118ms/step - loss: 0.3500 - acc: 0.8778\n",
            "Test Epochs number60/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5266 - acc: 0.8386\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number61/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3433 - acc: 0.8783\n",
            "Test Epochs number61/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5500 - acc: 0.8258\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number62/100\n",
            "624/624 [==============================] - 73s 118ms/step - loss: 0.3519 - acc: 0.8756\n",
            "Test Epochs number62/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5164 - acc: 0.8378\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number63/100\n",
            "624/624 [==============================] - 73s 118ms/step - loss: 0.3463 - acc: 0.8760\n",
            "Test Epochs number63/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5125 - acc: 0.8359\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number64/100\n",
            "624/624 [==============================] - 74s 118ms/step - loss: 0.3417 - acc: 0.8787\n",
            "Test Epochs number64/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5057 - acc: 0.8436\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number65/100\n",
            "624/624 [==============================] - 73s 118ms/step - loss: 0.3424 - acc: 0.8786\n",
            "Test Epochs number65/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5098 - acc: 0.8391\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number66/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3375 - acc: 0.8812\n",
            "Test Epochs number66/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5088 - acc: 0.8405\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number67/100\n",
            "624/624 [==============================] - 74s 118ms/step - loss: 0.3393 - acc: 0.8786\n",
            "Test Epochs number67/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5208 - acc: 0.8373\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number68/100\n",
            "624/624 [==============================] - 73s 118ms/step - loss: 0.3297 - acc: 0.8835\n",
            "Test Epochs number68/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5054 - acc: 0.8374\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number69/100\n",
            "624/624 [==============================] - 74s 118ms/step - loss: 0.3329 - acc: 0.8811\n",
            "Test Epochs number69/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 0.5778 - acc: 0.8246\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number70/100\n",
            "624/624 [==============================] - 74s 118ms/step - loss: 0.3298 - acc: 0.8824\n",
            "Test Epochs number70/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5851 - acc: 0.8248\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number71/100\n",
            "624/624 [==============================] - 74s 118ms/step - loss: 0.3289 - acc: 0.8816\n",
            "Test Epochs number71/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5306 - acc: 0.8400\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number72/100\n",
            "624/624 [==============================] - 74s 119ms/step - loss: 0.3276 - acc: 0.8821\n",
            "Test Epochs number72/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5205 - acc: 0.8419\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number73/100\n",
            "624/624 [==============================] - 74s 119ms/step - loss: 0.3275 - acc: 0.8823\n",
            "Test Epochs number73/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5004 - acc: 0.8430\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number74/100\n",
            "624/624 [==============================] - 74s 119ms/step - loss: 0.3237 - acc: 0.8857\n",
            "Test Epochs number74/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5003 - acc: 0.8453\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number75/100\n",
            "624/624 [==============================] - 74s 119ms/step - loss: 0.3224 - acc: 0.8847\n",
            "Test Epochs number75/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 0.6091 - acc: 0.8179\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number76/100\n",
            "624/624 [==============================] - 74s 119ms/step - loss: 0.3170 - acc: 0.8868\n",
            "Test Epochs number76/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5372 - acc: 0.8373\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number77/100\n",
            "624/624 [==============================] - 74s 119ms/step - loss: 0.3193 - acc: 0.8882\n",
            "Test Epochs number77/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5847 - acc: 0.8256\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number78/100\n",
            "624/624 [==============================] - 74s 119ms/step - loss: 0.3132 - acc: 0.8878\n",
            "Test Epochs number78/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5467 - acc: 0.8314\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number79/100\n",
            "624/624 [==============================] - 74s 119ms/step - loss: 0.3124 - acc: 0.8880\n",
            "Test Epochs number79/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.4959 - acc: 0.8496\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number80/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3117 - acc: 0.8890\n",
            "Test Epochs number80/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5168 - acc: 0.8455\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number81/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3099 - acc: 0.8916\n",
            "Test Epochs number81/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5603 - acc: 0.8322\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number82/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3107 - acc: 0.8891\n",
            "Test Epochs number82/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5157 - acc: 0.8400\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number83/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3051 - acc: 0.8917\n",
            "Test Epochs number83/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5471 - acc: 0.8338\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number84/100\n",
            "624/624 [==============================] - 73s 118ms/step - loss: 0.3043 - acc: 0.8920\n",
            "Test Epochs number84/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5965 - acc: 0.8241\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number85/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3058 - acc: 0.8903\n",
            "Test Epochs number85/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 0.5649 - acc: 0.8329\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number86/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3008 - acc: 0.8934\n",
            "Test Epochs number86/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5252 - acc: 0.8420\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number87/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.3062 - acc: 0.8913\n",
            "Test Epochs number87/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5249 - acc: 0.8396\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number88/100\n",
            "624/624 [==============================] - 73s 118ms/step - loss: 0.2968 - acc: 0.8952\n",
            "Test Epochs number88/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5359 - acc: 0.8371\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number89/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.2994 - acc: 0.8934\n",
            "Test Epochs number89/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5210 - acc: 0.8404\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number90/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.2973 - acc: 0.8951\n",
            "Test Epochs number90/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5129 - acc: 0.8468\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number91/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.2967 - acc: 0.8945\n",
            "Test Epochs number91/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5323 - acc: 0.8372\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number92/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.2949 - acc: 0.8947\n",
            "Test Epochs number92/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5497 - acc: 0.8398\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number93/100\n",
            "624/624 [==============================] - 73s 116ms/step - loss: 0.2898 - acc: 0.8979\n",
            "Test Epochs number93/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5324 - acc: 0.8394\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number94/100\n",
            "624/624 [==============================] - 72s 115ms/step - loss: 0.2922 - acc: 0.8958\n",
            "Test Epochs number94/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 0.5684 - acc: 0.8349\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number95/100\n",
            "624/624 [==============================] - 72s 115ms/step - loss: 0.2872 - acc: 0.8972\n",
            "Test Epochs number95/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5357 - acc: 0.8425\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number96/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.2846 - acc: 0.8998\n",
            "Test Epochs number96/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5996 - acc: 0.8251\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number97/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.2839 - acc: 0.9009\n",
            "Test Epochs number97/100\n",
            "156/156 [==============================] - 4s 27ms/step - loss: 0.5366 - acc: 0.8438\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number98/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.2885 - acc: 0.8968\n",
            "Test Epochs number98/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5186 - acc: 0.8431\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number99/100\n",
            "624/624 [==============================] - 73s 117ms/step - loss: 0.2898 - acc: 0.8952\n",
            "Test Epochs number99/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5885 - acc: 0.8296\n",
            "  \n",
            "------------------------\n",
            "TrainEpochs number100/100\n",
            "624/624 [==============================] - 73s 118ms/step - loss: 0.2826 - acc: 0.8989\n",
            "Test Epochs number100/100\n",
            "156/156 [==============================] - 4s 28ms/step - loss: 0.5039 - acc: 0.8514\n",
            "  \n",
            "------------------------\n",
            "<DatasetV1Adapter shapes: ((?, 32, 32, 3), (?, 10)), types: (tf.float32, tf.float32)> <DatasetV1Adapter shapes: ((?, 32, 32, 3), (?, 10)), types: (tf.float32, tf.float32)>\n",
            "total time 7553.217262506485\n",
            "----------------END---------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I29GQFN40XFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}